import os
import torch
import numpy as np
import tempfile
from moviepy import VideoFileClip, TextClip, CompositeVideoClip, ColorClip, ImageSequenceClip
import folder_paths
import langid
import re

cache_dir = folder_paths.get_temp_directory()
PUNCTUATION = "ï¼‚ï¼ƒï¼„ï¼…ï¼†ï¼‡ï¼ˆï¼‰ï¼Šï¼‹ï¼Œï¼ï¼ï¼šï¼›ï¼œï¼ï¼ï¼ ï¼»ï¼¼ï¼½ï¼¾ï¼¿ï½€ï½›ï½œï½ï½ï½Ÿï½ ï½¢ï½£ï½¤ã€ã€ƒã€ã€ã€ã€‘ã€–ã€—ã€˜ã€™ã€šã€›ã€œã€ã€ã€Ÿâ€“â€”â€˜â€™â€›â€â€Ÿâ€¦â€§ï¹." \
              "!?(),;:[]{}<>\"+-=&^*%$#@/" \
              "ã€‚ï¼Ÿï¼ï¼Œã€ï¼›ï¼šâ€œâ€â€˜'ã€Šã€‹ã€ˆã€‰ã€Œã€ã€”ã€•â€”â€”Â·~`-"

def reverse_convert_to_list(text):
    
    pattern = r"\((\d+\.\d+),\s*(\d+\.\d+)\)\s*(.*)"
    result = []
    
    for line in text.strip().split("\n"):
        match = re.match(pattern, line)
        if match:
            start = float(match.group(1))
            end = float(match.group(2))
            content = match.group(3)
            result.append([start, end, content])
    
    return result

def hex_to_rgb(hex_color: str):
    hex_color = hex_color.lstrip('#')
    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))

def parse_margin(margin_str: str, default_margin: int):
    if not margin_str: return (default_margin, default_margin)
    try:
        parts = [int(p.strip()) for p in margin_str.split(',')]
        if len(parts) == 1: return (parts[0], parts[0])
        if len(parts) == 2: return tuple(parts)
        if len(parts) == 4: return tuple(parts)
    except (ValueError, IndexError): pass
    return (default_margin, default_margin)

def get_font_list():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    font_dir = os.path.join(current_dir, "fonts")
    font_files = []
    if os.path.exists(font_dir):
        for file in os.listdir(font_dir):
            if file.lower().endswith(('.ttf', '.otf', '.ttc')):
                font_files.append(file)
    return font_files

def clean_punctuation_from_subtitles(subtitles, lang='en'):
    APOS_PLACEHOLDER = 'Â¤'
    HYPHEN_PLACEHOLDER = 'Â§'

    punct_nuke_pattern = re.compile(f"[{re.escape(PUNCTUATION)}]+")
    
    cleaned_subtitles = []
    for start, end, text in subtitles:
        if lang == 'en':
            
            processed_text = re.sub(r"(?<=[a-zA-Z])['â€™â€˜](?=[a-zA-Z])", APOS_PLACEHOLDER, text)
            processed_text = re.sub(r"(?<=[a-zA-Z0-9])-(?=[a-zA-Z0-9])", HYPHEN_PLACEHOLDER, processed_text)
            processed_text = punct_nuke_pattern.sub(" ", processed_text)

            processed_text = processed_text.replace(APOS_PLACEHOLDER, "'")
            processed_text = processed_text.replace(HYPHEN_PLACEHOLDER, "-")
        else:
            
            processed_text = punct_nuke_pattern.sub(" ", text)

        cleaned_text = re.sub(r'\s+', ' ', processed_text).strip()
        
        if cleaned_text:
            cleaned_subtitles.append((start, end, cleaned_text))
            
    return cleaned_subtitles



# ==============================================================================
#  NODE 1: STATIC SUBTITLES
# ==============================================================================

def smart_wrap_static(text, max_width_for_wrapping, font, font_size, language='en', stroke_width=0):
    if not text.strip(): return ""

    if language == 'zh': 
        lines, current_line = [], ''
        for char in text:
            test_line = f"{current_line}{char}"
            line_width = TextClip(text=test_line, font=font, font_size=font_size, stroke_width=stroke_width, method='label').w
            if line_width <= max_width_for_wrapping: current_line = test_line
            else: lines.append(current_line); current_line = char
        lines.append(current_line)
        corrected_lines = list(lines)
        for i in range(1, len(corrected_lines)):
            while corrected_lines[i] and corrected_lines[i][0] in PUNCTUATION:
                p = corrected_lines[i][0]
                if corrected_lines[i-1]: corrected_lines[i-1] += p; corrected_lines[i] = corrected_lines[i][1:]
                else: break
        return '\n'.join([line for line in corrected_lines if line.strip()])
    else: 
        words = text.split(' ')
        lines, current_line_words = [], []
        for word in words:
            if not word: continue
            temp_line_words = current_line_words + [word]
            test_line = " ".join(temp_line_words)
            line_width = TextClip(text=test_line, font=font, font_size=font_size, stroke_width=stroke_width, method='label').w
            if line_width <= max_width_for_wrapping: current_line_words.append(word)
            else:
                if word and word[0] in PUNCTUATION and len(current_line_words) > 0:
                    word_to_move = current_line_words.pop()
                    lines.append(" ".join(current_line_words))
                    current_line_words = [word_to_move, word]
                else:
                    lines.append(" ".join(current_line_words))
                    current_line_words = [word]
        if current_line_words: lines.append(" ".join(current_line_words))
        return '\n'.join([line for line in lines if line.strip()])

def create_static_subtitle_clip(text, start_time, end_time, video_width, video_height, **kwargs):
    font_size = kwargs.get('font_size', 24)
    font_path = kwargs.get('font_path', 'msyh.ttc')
    font_color = kwargs.get('font_color', (255, 255, 255))
    bg_color = kwargs.get('bg_color', (0, 0, 0))
    bg_opacity = kwargs.get('bg_opacity', 0.5)
    stroke_color = kwargs.get('stroke_color', font_color)
    stroke_width = kwargs.get('stroke_width', 1.0)
    interline = kwargs.get('interline', 4)
    margin_str = kwargs.get('margin_tuple', '')
    text_align = kwargs.get('text_align', 'left')
    block_horizontal_align = kwargs.get('block_horizontal_align', 'center')
    vertical_pos_offset = kwargs.get('vertical_pos_offset', 0)
    line_width_ratio = kwargs.get('line_width_ratio', 0.8)
    language = kwargs.get('language', 'en')

    allowed_width = int(video_width * line_width_ratio)
    wrapped_text = smart_wrap_static(text, allowed_width, font_path, font_size, language, stroke_width)

    if not wrapped_text.strip():
        return ColorClip(size=(1, 1), color=(0,0,0), duration=end_time-start_time).with_opacity(0).with_start(start_time)

    bg_color_with_alpha = bg_color + (int(bg_opacity * 255),)
    default_inner_margin = int(font_size * 0.2)
    inner_margin_tuple = parse_margin(margin_str, default_inner_margin)

    subtitle_block = TextClip(
        text=wrapped_text, font=font_path, font_size=font_size, color=f'rgb{font_color}',
        bg_color=bg_color_with_alpha, stroke_color=f'rgb{stroke_color}', stroke_width=stroke_width,
        method='label', text_align=text_align, margin=inner_margin_tuple, interline=interline
    )
    subtitle_block = subtitle_block.with_start(start_time).with_duration(end_time - start_time)
    
    y_pos = video_height - subtitle_block.h - vertical_pos_offset
    return subtitle_block.with_position((block_horizontal_align, y_pos))

class StaticSubtitlesToVideoMW:
    @classmethod
    def INPUT_TYPES(cls):
        font_list = get_font_list()
        return {
            "required": {
                "è§†é¢‘": ("IMAGE",), "å¸§ç‡": ("FLOAT", {"forceInput": True}),
                "å­—å¹•æ–‡æœ¬": ("STRING", {"forceInput": True, "tooltip": "é€å¥æ—¶é—´æˆ³"}),
                "å­—ä½“": (font_list, {"tooltip": "å­—å¹•å­—ä½“ï¼Œæ”¾åœ¨èŠ‚ç‚¹ç›®å½• fonts ä¸‹"}), 
                "å­—ä½“å¤§å°æ¯”ä¾‹": ("FLOAT", {"default": 0.05, "min": 0.01, "max": 0.2, "step": 0.01}, {"tooltip": "å­—å¹•å­—ä½“å¤§å°ä¸è§†é¢‘å®½åº¦çš„æ¯”ä¾‹"}),
                "å­—ä½“é¢œè‰²": ("STRING", {"default": "#FFFFFF", "tooltip": "å­—ä½“é¢œè‰²ï¼Œæ ¼å¼ä¸º#RRGGBB"}), 
                "å­—ä½“èƒŒæ™¯è‰²": ("STRING", {"default": "#0000FF", "tooltip": "å­—ä½“èƒŒæ™¯é¢œè‰²ï¼Œæ ¼å¼ä¸º#RRGGBB"}),
                "èƒŒæ™¯é€æ˜åº¦": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.1}, {"tooltip": "å­—å¹•èƒŒæ™¯é€æ˜åº¦ï¼Œ0ä¸ºå®Œå…¨é€æ˜ï¼Œ1ä¸ºå®Œå…¨ä¸é€æ˜"}),
            },
            "optional": {
                "å­—å¹•å®½åº¦æ¯”ä¾‹": ("FLOAT", {"default": 0.9, "min": 0.1, "max": 1.0, "step": 0.05}, {"tooltip": "å­—å¹•å®½åº¦ä¸è§†é¢‘å®½åº¦çš„æ¯”ä¾‹"}),
                "å‚ç›´å‘ä¸Šåç§»": ("INT", {"default": 30, "min": 0, "max": 2000, "step": 5}, {"tooltip": "å­—å¹•å—å‚ç›´å‘ä¸Šåç§»é‡"}),
                # "å­—å¹•å—æ°´å¹³ä½ç½®": (["left", "center", "right"], {"default": "center"}, {"tooltip": "å­—å¹•å—æ°´å¹³ä½ç½®"}),
                "æ–‡æœ¬è¡Œå¯¹é½æ–¹å¼": (["left", "center", "right"], {"default": "center"}, {"tooltip": "æ–‡æœ¬è¡Œå¯¹é½æ–¹å¼"}),
                "è¡Œé—´è·": ("INT", {"default": 4, "min": 0, "max": 100, "step": 1}, {"tooltip": "å­—å¹•è¡Œé—´è·"}),
                "æè¾¹å®½åº¦": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 20.0, "step": 0.1}, {"tooltip": "å­—å¹•å­—ä½“æè¾¹å®½åº¦"}),
                "æè¾¹é¢œè‰²": ("STRING", {"default": "", "tooltip": "ç•™ç©ºåˆ™ä½¿ç”¨ä¸å­—ä½“ç›¸åŒçš„é¢œè‰², æ ¼å¼ä¸º #RRGGBB"}),
                "è¡Œå†…å­—ä½“ä¸Šè¾¹è·": ("INT", {"default": 5, "min": 0, "max": 100, "step": 1}, {"tooltip": "å­—å¹•å­—ä½“ä¸èƒŒæ™¯æ¡†é¡¶éƒ¨çš„é—´è·"}),
                "è¡Œå†…å­—ä½“ä¸‹è¾¹è·": ("INT", {"default": 10, "min": 0, "max": 100, "step": 1}, {"tooltip": "å­—å¹•å­—ä½“ä¸èƒŒæ™¯æ¡†åº•éƒ¨çš„é—´è·"}),
                "å»é™¤æ ‡ç‚¹ç¬¦å·": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦å»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·å¹¶æ›¿æ¢ä¸ºç©ºæ ¼"}),
            }
        }
    RETURN_TYPES = ("IMAGE",); RETURN_NAMES = ("é™æ€å­—å¹•è§†é¢‘",)
    FUNCTION = "add_subtitles"; CATEGORY = "ğŸ¤MW/MW-ASR"

    def add_subtitles(self, è§†é¢‘, å¸§ç‡, å­—å¹•æ–‡æœ¬, å­—ä½“, å­—ä½“å¤§å°æ¯”ä¾‹, å­—ä½“é¢œè‰², å­—ä½“èƒŒæ™¯è‰², èƒŒæ™¯é€æ˜åº¦,
                     å­—å¹•å®½åº¦æ¯”ä¾‹=0.9, å‚ç›´å‘ä¸Šåç§»=30, å­—å¹•å—æ°´å¹³ä½ç½®="center", æ–‡æœ¬è¡Œå¯¹é½æ–¹å¼="center",
                     è¡Œé—´è·=4, æè¾¹å®½åº¦=1.0, æè¾¹é¢œè‰²="", è¡Œå†…å­—ä½“ä¸Šè¾¹è·=5, è¡Œå†…å­—ä½“ä¸‹è¾¹è·=10, å»é™¤æ ‡ç‚¹ç¬¦å·=False):

        if isinstance(è§†é¢‘, torch.Tensor):
            video_np = è§†é¢‘.cpu().numpy()
            if video_np.ndim == 5 and video_np.shape[0] == 1: video_np = video_np.squeeze(0)
            if video_np.dtype == np.float32 or video_np.dtype == np.float64:
                 video_np = (video_np * 255).astype(np.uint8)
        else: raise ValueError("è¾“å…¥è§†é¢‘æ ¼å¼ä¸æ­£ç¡®")
        
        temp_input_path = tempfile.NamedTemporaryFile(suffix='.mp4', dir=cache_dir, delete=False).name
        temp_output_path = tempfile.NamedTemporaryFile(suffix='.mp4', dir=cache_dir, delete=False).name
        clip = ImageSequenceClip(list(video_np), fps=å¸§ç‡)
        clip.write_videofile(temp_input_path, codec='libx264', audio_codec='aac')

        font_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "fonts", å­—ä½“)
        font_color_rgb, bg_color_rgb = hex_to_rgb(å­—ä½“é¢œè‰²), hex_to_rgb(å­—ä½“èƒŒæ™¯è‰²)
        stroke_color_rgb = hex_to_rgb(æè¾¹é¢œè‰²) if æè¾¹é¢œè‰².strip() else font_color_rgb

        try: 
            subtitles_data = reverse_convert_to_list(å­—å¹•æ–‡æœ¬)
        except ValueError: raise ValueError("é”™è¯¯ï¼šå­—å¹•æ–‡æœ¬ä¸æ˜¯æœ‰æ•ˆçš„æ ¼å¼ã€‚")
        
        if subtitles_data:
            lang, _ = langid.classify(å­—å¹•æ–‡æœ¬)
        else: lang = 'en'
        
        if å»é™¤æ ‡ç‚¹ç¬¦å·:
            subtitles_data = clean_punctuation_from_subtitles(subtitles_data, lang=lang)

        video_clip_in = VideoFileClip(temp_input_path)
        video_width, video_height = video_clip_in.size
        
        font_size_px = int(video_width * å­—ä½“å¤§å°æ¯”ä¾‹)

        subtitle_settings = {
            'font_size': font_size_px, 'font_path': font_path, 'font_color': font_color_rgb,
            'bg_color': bg_color_rgb, 'bg_opacity': èƒŒæ™¯é€æ˜åº¦, 'line_width_ratio': å­—å¹•å®½åº¦æ¯”ä¾‹,
            'vertical_pos_offset': å‚ç›´å‘ä¸Šåç§», 'interline': è¡Œé—´è·, 'stroke_width': æè¾¹å®½åº¦,
            'stroke_color': stroke_color_rgb, 'margin_tuple': f"5, {è¡Œå†…å­—ä½“ä¸Šè¾¹è·}, 5, {è¡Œå†…å­—ä½“ä¸‹è¾¹è·}", 'text_align': æ–‡æœ¬è¡Œå¯¹é½æ–¹å¼,
            'block_horizontal_align': å­—å¹•å—æ°´å¹³ä½ç½®, 'language': lang,
        }
        
        subtitle_clips = [create_static_subtitle_clip(text, start, end, video_width, video_height, **subtitle_settings) 
                          for start, end, text in subtitles_data]
        
        final_clip = CompositeVideoClip([video_clip_in] + subtitle_clips)
        final_clip.write_videofile(temp_output_path, codec='libx264', audio_codec='aac', threads=4, preset='fast')
        
        output_clip = VideoFileClip(temp_output_path)
        output_frames = [torch.from_numpy(frame).float() / 255.0 for frame in output_clip.iter_frames()]
        output_clip.close()

        return (torch.stack(output_frames),)

# ==============================================================================
#  NODE 2: DYNAMIC SUBTITLES
# ==============================================================================

def generate_dynamic_subtitles(subtitles, video_width, video_height, **kwargs):
    font_path = kwargs.get('font_path', 'msyh.ttc')
    font_size = kwargs.get('font_size', 24)
    font_color = kwargs.get('font_color', (255, 255, 255))
    bg_color = kwargs.get('bg_color', (0, 0, 0))
    bg_opacity = kwargs.get('bg_opacity', 0.5)
    stroke_color = kwargs.get('stroke_color', font_color)
    stroke_width = kwargs.get('stroke_width', 0.5)
    line_width_ratio = kwargs.get('line_width_ratio', 0.8)
    vertical_pos_offset = kwargs.get('vertical_pos_offset', 0)
    interline = kwargs.get('interline', 10)
    clearance_threshold = kwargs.get('clearance_threshold', 2.0)
    margin_str = kwargs.get('margin_tuple', '')
    language = kwargs.get('language', 'en')
    max_lines = kwargs.get('max_lines', 3)
    text_align = 'left'
    
    allowed_width = int(video_width * line_width_ratio)
    bg_color_with_alpha = bg_color + (int(bg_opacity * 255),)
    default_inner_margin = int(font_size * 0.1)
    inner_margin_tuple = parse_margin(margin_str, default_inner_margin)
    is_chinese = language != 'en'

    if not subtitles: return []
    blocks = []
    current_block = []
    
    last_word_end_time = -clearance_threshold - 1
    for i, (start, end, word) in enumerate(subtitles):
        
        if start - last_word_end_time > clearance_threshold:
            if current_block: 
                blocks.append(current_block)
            current_block = [] 
        current_block.append({'start': start, 'end': end, 'text': word})
        last_word_end_time = end
    if current_block: blocks.append(current_block)

    all_clips = []
    for block in blocks:
        
        lines = [""] 
        for i, word_data in enumerate(block):
            
            word_to_add = word_data['text'].strip()
            if not word_to_add:
                
                continue

            current_line = lines[-1]
            if is_chinese:
                
                test_line = current_line + word_to_add
            else:
                
                separator = " " if current_line else ""
                test_line = current_line + separator + word_to_add

            test_clip = TextClip(text=test_line, font=font_path, font_size=font_size, 
                                 stroke_width=stroke_width, method='label')
            
            if test_clip.w <= allowed_width:
                
                lines[-1] = test_line
            else:
                
                lines.append(word_to_add)
            visible_lines = lines[-max_lines:]

            line_clips = [TextClip(text=line, font=font_path, font_size=font_size, color=f'rgb{font_color}', 
                                   bg_color=f'rgba{bg_color_with_alpha}', stroke_color=f'rgb{stroke_color}', 
                                   stroke_width=stroke_width, method='label', 
                                   text_align=text_align, margin=inner_margin_tuple) 
                          for line in visible_lines if line.strip()]
            
            if not line_clips: continue
            total_height = sum(lc.h for lc in line_clips) + max(0, len(line_clips) - 1) * interline
            
            max_line_width = max(lc.w for lc in line_clips) if line_clips else 0
            canvas_size = (max_line_width, int(total_height))
            
            y_pos_on_canvas = 0
            positioned_clips = []
            for lc in line_clips:
                
                positioned_clip = lc.with_position((0, y_pos_on_canvas))
                positioned_clips.append(positioned_clip)
                y_pos_on_canvas += lc.h + interline
            
            moment_canvas = CompositeVideoClip(positioned_clips, size=canvas_size).with_opacity(1)
            
            start_time = word_data['start']
            
            end_time = block[i+1]['start'] if i + 1 < len(block) else block[-1]['end']
            duration = end_time - start_time
            if duration <= 0.01: continue
            y_final = video_height - moment_canvas.h - vertical_pos_offset
            final_clip_for_moment = moment_canvas.with_start(start_time).with_duration(duration).with_position(('center', y_final))
            all_clips.append(final_clip_for_moment)
            
    return all_clips

class DynamicSubtitlesToVideoMW:
    @classmethod
    def INPUT_TYPES(cls):
        font_list = get_font_list()
        return {
            "required": {
                "è§†é¢‘": ("IMAGE",), 
                "å¸§ç‡": ("FLOAT", {"forceInput": True, "tooltip": "è§†é¢‘å¸§ç‡"}),
                "å­—å¹•æ–‡æœ¬": ("STRING", {"forceInput": True, "tooltip": "é€è¯æ—¶é—´æˆ³"}),
                "å­—ä½“": (font_list, {"tooltip": "å­—å¹•å­—ä½“, æ”¾åœ¨èŠ‚ç‚¹æ–‡ä»¶å¤¹ fonts ä¸‹"}), 
                "å­—ä½“å¤§å°æ¯”ä¾‹": ("FLOAT", {"default": 0.05, "min": 0.01, "max": 0.2, "step": 0.01, "tooltip": "å­—å¹•å­—ä½“å¤§å°ä¸è§†é¢‘å®½åº¦çš„æ¯”ä¾‹"}),
                "å­—ä½“é¢œè‰²": ("STRING", {"default": "#FFFFFF", "tooltip": "å­—å¹•å­—ä½“é¢œè‰², æ ¼å¼ä¸º #RRGGBB"}), 
                "å­—ä½“èƒŒæ™¯è‰²": ("STRING", {"default": "#000000", "tooltip": "å­—å¹•å­—ä½“èƒŒæ™¯é¢œè‰², æ ¼å¼ä¸º #RRGGBB"}), 
                "èƒŒæ™¯é€æ˜åº¦": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.1, "tooltip": "å­—å¹•å­—ä½“èƒŒæ™¯é€æ˜åº¦, 0ä¸ºå®Œå…¨é€æ˜, 1ä¸ºå®Œå…¨ä¸é€æ˜"}),
            },
            "optional": {
                "æœ€å¤§è¡Œæ•°": ("INT", {"default": 2, "min": 1, "max": 10, "step": 1, "tooltip": "å±å¹•ä¸ŠåŒæ—¶æ˜¾ç¤ºçš„æœ€å¤§å­—å¹•è¡Œæ•°"}),
                "å­—å¹•å®½åº¦æ¯”ä¾‹": ("FLOAT", {"default": 0.9, "min": 0.1, "max": 1.0, "step": 0.05, "tooltip": "å­—å¹•å®½åº¦ä¸è§†é¢‘å®½åº¦çš„æ¯”ä¾‹"}),
                "å‚ç›´å‘ä¸Šåç§»": ("INT", {"default": 50, "min": 0, "max": 2000, "step": 10, "tooltip": "å­—å¹•å‚ç›´å‘ä¸Šåç§»çš„åƒç´ æ•°"}),
                "è¡Œé—´è·": ("INT", {"default": 3, "min": 0, "max": 100, "step": 1, "tooltip": "å­—å¹•è¡Œé—´è·çš„åƒç´ æ•°"}),
                "æè¾¹å®½åº¦": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 20.0, "step": 0.1, "tooltip": "å­—å¹•å­—ä½“æè¾¹å®½åº¦, 0ä¸ºä¸æè¾¹"}),
                "æè¾¹é¢œè‰²": ("STRING", {"default": "", "tooltip": "ç•™ç©ºåˆ™ä½¿ç”¨ä¸å­—ä½“ç›¸åŒçš„é¢œè‰², æ ¼å¼ä¸º #RRGGBB"}),
                "è¡Œå†…å­—ä½“ä¸Šè¾¹è·": ("INT", {"default": 5, "min": 0, "max": 50, "step": 1, "tooltip": "å­—å¹•å­—ä½“ä¸èƒŒæ™¯æ¡†é¡¶éƒ¨çš„é—´è·"}),
                "è¡Œå†…å­—ä½“ä¸‹è¾¹è·": ("INT", {"default": 10, "min": 0, "max": 50, "step": 1, "tooltip": "å­—å¹•å­—ä½“ä¸èƒŒæ™¯æ¡†åº•éƒ¨çš„é—´è·"}),
                "æ¸…ç©ºé˜ˆå€¼": ("FLOAT", {"default": 2.0, "min": 0.1, "max": 10.0, "step": 0.1, "tooltip": "å‰åä¸¤å¥è¯ä¹‹é—´é™éŸ³è¶…è¿‡è¯¥ç§’æ•°ï¼Œåˆ™æ¸…ç©ºå­—å¹•é‡æ–°å¼€å§‹"}),
                "å»é™¤æ ‡ç‚¹ç¬¦å·": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦å»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·"}),
            }
        }
    RETURN_TYPES = ("IMAGE",); RETURN_NAMES = ("åŠ¨æ€å­—å¹•è§†é¢‘",)
    FUNCTION = "add_dynamic_subtitles"; CATEGORY = "ğŸ¤MW/MW-ASR"
    
    def add_dynamic_subtitles(self, è§†é¢‘, å¸§ç‡, å­—å¹•æ–‡æœ¬, å­—ä½“, å­—ä½“å¤§å°æ¯”ä¾‹, å­—ä½“é¢œè‰², å­—ä½“èƒŒæ™¯è‰², èƒŒæ™¯é€æ˜åº¦, 
                     æœ€å¤§è¡Œæ•°=3, å­—å¹•å®½åº¦æ¯”ä¾‹=0.9, å‚ç›´å‘ä¸Šåç§»=50, è¡Œé—´è·=10, æè¾¹å®½åº¦=1.0, 
                     æè¾¹é¢œè‰²="", è¡Œå†…å­—ä½“ä¸Šè¾¹è·=5, è¡Œå†…å­—ä½“ä¸‹è¾¹è·=5, æ¸…ç©ºé˜ˆå€¼=2.0, å»é™¤æ ‡ç‚¹ç¬¦å·=False):
        if isinstance(è§†é¢‘, torch.Tensor):
            video_np = è§†é¢‘.cpu().numpy()
            if video_np.ndim == 4: 
                
                if video_np.shape[0] == 1 and è§†é¢‘.dim() == 4:
                   video_np = np.squeeze(video_np, axis=0)
            elif video_np.ndim == 5: 
                if video_np.shape[0] == 1:
                    video_np = np.squeeze(video_np, axis=0)
                else:
                    raise ValueError("è¾“å…¥è§†é¢‘æ‰¹æ¬¡å¤§å°åº”ä¸º1")

            if video_np.dtype == np.float32 or video_np.dtype == np.float64:
                 video_np = (video_np * 255).astype(np.uint8)
        else: raise ValueError("è¾“å…¥è§†é¢‘æ ¼å¼ä¸æ­£ç¡®")
        
        temp_input_path = tempfile.NamedTemporaryFile(suffix='.mp4', dir=cache_dir, delete=False).name
        temp_output_path = tempfile.NamedTemporaryFile(suffix='.mp4', dir=cache_dir, delete=False).name

        frames_list = [frame for frame in video_np]
        clip = ImageSequenceClip(frames_list, fps=å¸§ç‡)
        clip.write_videofile(temp_input_path, codec='libx264', audio=False, threads=4, preset='fast', logger=None)

        font_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "fonts", å­—ä½“)
        font_color_rgb, bg_color_rgb = hex_to_rgb(å­—ä½“é¢œè‰²), hex_to_rgb(å­—ä½“èƒŒæ™¯è‰²)
        stroke_color_rgb = hex_to_rgb(æè¾¹é¢œè‰²) if æè¾¹é¢œè‰².strip() else font_color_rgb

        try: 
            subtitles_data = reverse_convert_to_list(å­—å¹•æ–‡æœ¬)
        except ValueError: 
             raise ValueError("é”™è¯¯ï¼šå­—å¹•æ–‡æœ¬ä¸æ˜¯æœ‰æ•ˆçš„æ ¼å¼ã€‚")
        
        if subtitles_data:
            lang, _ = langid.classify(å­—å¹•æ–‡æœ¬)
        else: 
            lang = 'en' 
        
        if å»é™¤æ ‡ç‚¹ç¬¦å·:
            subtitles_data = clean_punctuation_from_subtitles(subtitles_data, lang=lang)
            
        video_clip_in = VideoFileClip(temp_input_path)
        video_width, video_height = video_clip_in.size
        
        font_size_px = int(video_height * å­—ä½“å¤§å°æ¯”ä¾‹)
        
        subtitle_settings = {
            'font_path': font_path, 'font_size': font_size_px, 'font_color': font_color_rgb,
            'bg_color': bg_color_rgb, 'bg_opacity': èƒŒæ™¯é€æ˜åº¦, 'line_width_ratio': å­—å¹•å®½åº¦æ¯”ä¾‹,
            'vertical_pos_offset': å‚ç›´å‘ä¸Šåç§», 'interline': è¡Œé—´è·, 'stroke_width': æè¾¹å®½åº¦,
            'stroke_color': stroke_color_rgb, 'margin_tuple': f"5, {è¡Œå†…å­—ä½“ä¸Šè¾¹è·}, 5, {è¡Œå†…å­—ä½“ä¸‹è¾¹è·}", 'clearance_threshold': æ¸…ç©ºé˜ˆå€¼,
            'language': lang, 'max_lines': æœ€å¤§è¡Œæ•°,
        }

        subtitle_clips = generate_dynamic_subtitles(subtitles_data, video_width, video_height, **subtitle_settings)
        
        final_clip = CompositeVideoClip([video_clip_in] + subtitle_clips)
        final_clip.write_videofile(temp_output_path, codec='libx264', audio=False, threads=4, preset='fast', logger=None)
        
        output_clip = VideoFileClip(temp_output_path)
        output_frames = [torch.from_numpy(frame).float() / 255.0 for frame in output_clip.iter_frames()]
        output_clip.close()
        video_clip_in.close()

        return (torch.stack(output_frames),)